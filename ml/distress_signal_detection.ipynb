{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2925c55",
   "metadata": {},
   "source": [
    "# SafeNSound: Distress Signal Detection ML Development\n",
    "\n",
    "This notebook contains the machine learning development for the SafeNSound IoT-based distress signal detection system. The goal is to develop models that can accurately detect distress signals from audio data captured by sound sensors in semi-private rooms.\n",
    "\n",
    "## Project Overview\n",
    "- **Objective**: Detect distress signals (screams, calls for help, etc.) from ambient audio\n",
    "- **Data**: Audio recordings from IoT sound sensors\n",
    "- **Models**: Audio classification using deep learning and traditional ML approaches\n",
    "- **Deployment**: Real-time inference on IoT devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2440d7f5",
   "metadata": {},
   "source": [
    "## 1. Import Essential Libraries\n",
    "\n",
    "Import necessary libraries for audio processing, machine learning, and data visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42de6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Audio processing libraries\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Deep learning libraries (uncomment when needed)\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, LSTM, Dropout\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061319ac",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Audio Dataset\n",
    "\n",
    "Load audio files and create a dataset with labels (distress vs normal sounds). Explore the characteristics of the audio data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3199dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths (update these paths to your actual data location)\n",
    "DATA_PATH = \"../data/\"  # Update this path\n",
    "DISTRESS_PATH = os.path.join(DATA_PATH, \"distress/\")\n",
    "NORMAL_PATH = os.path.join(DATA_PATH, \"normal/\")\n",
    "\n",
    "def load_audio_files(directory, label, max_files=None):\n",
    "    \"\"\"Load audio files from directory and return file paths with labels\"\"\"\n",
    "    audio_data = []\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Warning: Directory {directory} does not exist. Creating sample data structure.\")\n",
    "        return []\n",
    "    \n",
    "    for i, filename in enumerate(os.listdir(directory)):\n",
    "        if filename.endswith(('.wav', '.mp3', '.flac')):\n",
    "            if max_files and i >= max_files:\n",
    "                break\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            audio_data.append({\n",
    "                'file_path': file_path,\n",
    "                'filename': filename,\n",
    "                'label': label\n",
    "            })\n",
    "    \n",
    "    return audio_data\n",
    "\n",
    "# Load dataset (update paths as needed)\n",
    "print(\"Loading audio dataset...\")\n",
    "distress_files = load_audio_files(DISTRESS_PATH, 'distress')\n",
    "normal_files = load_audio_files(NORMAL_PATH, 'normal')\n",
    "\n",
    "# Combine all files\n",
    "all_files = distress_files + normal_files\n",
    "dataset_df = pd.DataFrame(all_files)\n",
    "\n",
    "print(f\"Dataset loaded:\")\n",
    "print(f\"- Total files: {len(all_files)}\")\n",
    "print(f\"- Distress samples: {len(distress_files)}\")\n",
    "print(f\"- Normal samples: {len(normal_files)}\")\n",
    "\n",
    "if len(all_files) > 0:\n",
    "    print(\"\\nDataset preview:\")\n",
    "    print(dataset_df.head())\n",
    "    print(f\"\\nLabel distribution:\")\n",
    "    print(dataset_df['label'].value_counts())\n",
    "else:\n",
    "    print(\"\\nNote: No audio files found. Please add your audio data to the appropriate directories.\")\n",
    "    print(\"Expected structure:\")\n",
    "    print(\"- data/distress/ (for distress signal audio files)\")\n",
    "    print(\"- data/normal/ (for normal ambient sound files)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99768193",
   "metadata": {},
   "source": [
    "## 3. Audio Data Preprocessing and Feature Extraction\n",
    "\n",
    "Extract meaningful features from audio files including MFCC, spectral features, and other audio characteristics for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdbacee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_features(file_path, sr=22050, n_mfcc=13):\n",
    "    \"\"\"\n",
    "    Extract comprehensive audio features from an audio file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load audio file\n",
    "        y, sr = librosa.load(file_path, sr=sr)\n",
    "        \n",
    "        # Basic audio properties\n",
    "        duration = len(y) / sr\n",
    "        \n",
    "        # MFCC features (most important for speech/audio classification)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        mfcc_mean = np.mean(mfcc, axis=1)\n",
    "        mfcc_std = np.std(mfcc, axis=1)\n",
    "        \n",
    "        # Spectral features\n",
    "        spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]\n",
    "        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]\n",
    "        zero_crossing_rate = librosa.feature.zero_crossing_rate(y)[0]\n",
    "        \n",
    "        # Energy and tempo features\n",
    "        rms_energy = librosa.feature.rms(y=y)[0]\n",
    "        tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "        \n",
    "        # Aggregate features\n",
    "        features = {\n",
    "            'duration': duration,\n",
    "            'tempo': tempo,\n",
    "            'spectral_centroid_mean': np.mean(spectral_centroids),\n",
    "            'spectral_centroid_std': np.std(spectral_centroids),\n",
    "            'spectral_rolloff_mean': np.mean(spectral_rolloff),\n",
    "            'spectral_rolloff_std': np.std(spectral_rolloff),\n",
    "            'spectral_bandwidth_mean': np.mean(spectral_bandwidth),\n",
    "            'spectral_bandwidth_std': np.std(spectral_bandwidth),\n",
    "            'zero_crossing_rate_mean': np.mean(zero_crossing_rate),\n",
    "            'zero_crossing_rate_std': np.std(zero_crossing_rate),\n",
    "            'rms_energy_mean': np.mean(rms_energy),\n",
    "            'rms_energy_std': np.std(rms_energy),\n",
    "        }\n",
    "        \n",
    "        # Add MFCC features\n",
    "        for i, (mean_val, std_val) in enumerate(zip(mfcc_mean, mfcc_std)):\n",
    "            features[f'mfcc_{i+1}_mean'] = mean_val\n",
    "            features[f'mfcc_{i+1}_std'] = std_val\n",
    "            \n",
    "        return features\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def visualize_audio_sample(file_path, title=\"Audio Sample\"):\n",
    "    \"\"\"Visualize waveform and spectrogram of an audio file\"\"\"\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=22050)\n",
    "        \n",
    "        plt.figure(figsize=(15, 8))\n",
    "        \n",
    "        # Waveform\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.title(f'{title} - Waveform')\n",
    "        librosa.display.waveshow(y, sr=sr)\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Amplitude')\n",
    "        \n",
    "        # Spectrogram\n",
    "        plt.subplot(2, 2, 2)\n",
    "        D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "        librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='hz')\n",
    "        plt.title(f'{title} - Spectrogram')\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        \n",
    "        # MFCC\n",
    "        plt.subplot(2, 2, 3)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "        librosa.display.specshow(mfcc, sr=sr, x_axis='time')\n",
    "        plt.title(f'{title} - MFCC')\n",
    "        plt.colorbar()\n",
    "        \n",
    "        # Spectral features over time\n",
    "        plt.subplot(2, 2, 4)\n",
    "        spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
    "        frames = range(len(spectral_centroids))\n",
    "        t = librosa.frames_to_time(frames)\n",
    "        plt.plot(t, spectral_centroids, label='Spectral Centroid')\n",
    "        plt.title(f'{title} - Spectral Centroid')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Hz')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error visualizing {file_path}: {e}\")\n",
    "\n",
    "print(\"Audio processing functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844770d4",
   "metadata": {},
   "source": [
    "## 4. Split Data into Training and Testing Sets\n",
    "\n",
    "Extract features from all audio files and prepare the dataset for machine learning training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03553c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from all audio files\n",
    "if len(all_files) > 0:\n",
    "    print(\"Extracting features from audio files...\")\n",
    "    \n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    for i, file_info in enumerate(all_files):\n",
    "        print(f\"Processing file {i+1}/{len(all_files)}: {file_info['filename']}\")\n",
    "        \n",
    "        features = extract_audio_features(file_info['file_path'])\n",
    "        if features is not None:\n",
    "            features_list.append(features)\n",
    "            labels_list.append(file_info['label'])\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    features_df = pd.DataFrame(features_list)\n",
    "    features_df['label'] = labels_list\n",
    "    \n",
    "    print(f\"\\nFeature extraction completed!\")\n",
    "    print(f\"Features shape: {features_df.shape}\")\n",
    "    print(f\"Features extracted: {list(features_df.columns[:-1])}\")\n",
    "    \n",
    "    # Display feature statistics\n",
    "    print(\"\\nFeature dataset preview:\")\n",
    "    print(features_df.head())\n",
    "    \n",
    "    # Prepare data for machine learning\n",
    "    X = features_df.drop('label', axis=1)\n",
    "    y = features_df['label']\n",
    "    \n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    print(f\"\\nData split completed:\")\n",
    "    print(f\"Training set: {X_train_scaled.shape}\")\n",
    "    print(f\"Test set: {X_test_scaled.shape}\")\n",
    "    print(f\"Label classes: {label_encoder.classes_}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No audio files found. Please add audio data to continue with model training.\")\n",
    "    # Create dummy data for demonstration\n",
    "    print(\"Creating dummy dataset for demonstration...\")\n",
    "    np.random.seed(42)\n",
    "    X_train_scaled = np.random.random((100, 38))  # 38 features typically extracted\n",
    "    X_test_scaled = np.random.random((25, 38))\n",
    "    y_train = np.random.choice([0, 1], 100)\n",
    "    y_test = np.random.choice([0, 1], 25)\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.classes_ = np.array(['distress', 'normal'])\n",
    "    print(\"Dummy dataset created for demonstration purposes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497669e8",
   "metadata": {},
   "source": [
    "## 5. Choose and Train Models\n",
    "\n",
    "Train multiple machine learning models to find the best approach for distress signal detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049a6809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and train multiple models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', random_state=42),\n",
    "    'SVM Linear': SVC(kernel='linear', random_state=42)\n",
    "}\n",
    "\n",
    "trained_models = {}\n",
    "model_scores = {}\n",
    "\n",
    "print(\"Training models...\")\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    trained_models[name] = model\n",
    "    \n",
    "    # Cross-validation score\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
    "    model_scores[name] = {\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'cv_scores': cv_scores\n",
    "    }\n",
    "    \n",
    "    print(f\"{name} - CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# Display model comparison\n",
    "print(\"\\nModel Comparison (Cross-Validation Scores):\")\n",
    "print(\"-\" * 50)\n",
    "for name, scores in model_scores.items():\n",
    "    print(f\"{name:15s}: {scores['cv_mean']:.4f} (+/- {scores['cv_std'] * 2:.4f})\")\n",
    "\n",
    "# Select best model based on CV score\n",
    "best_model_name = max(model_scores.keys(), key=lambda x: model_scores[x]['cv_mean'])\n",
    "best_model = trained_models[best_model_name]\n",
    "\n",
    "print(f\"\\nBest model: {best_model_name}\")\n",
    "print(f\"Best CV score: {model_scores[best_model_name]['cv_mean']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef4650a",
   "metadata": {},
   "source": [
    "## 6. Evaluate Model Performance\n",
    "\n",
    "Assess model performance using various metrics and visualizations to understand how well the model detects distress signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf85e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all models on test set\n",
    "print(\"Evaluating models on test set...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    print(f\"\\n{name} Results:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(f\"\\nDetailed Classification Report:\")\n",
    "    target_names = [f\"Class {i} ({label})\" for i, label in enumerate(label_encoder.classes_)]\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "# Confusion Matrix for best model\n",
    "print(f\"\\nConfusion Matrix for {best_model_name}:\")\n",
    "y_pred_best = best_model.predict(X_test_scaled)\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=label_encoder.classes_, \n",
    "            yticklabels=label_encoder.classes_)\n",
    "plt.title(f'Confusion Matrix - {best_model_name}')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "# Plot model comparison\n",
    "plt.subplot(1, 2, 2)\n",
    "model_names = list(model_scores.keys())\n",
    "cv_means = [model_scores[name]['cv_mean'] for name in model_names]\n",
    "cv_stds = [model_scores[name]['cv_std'] for name in model_names]\n",
    "\n",
    "plt.bar(model_names, cv_means, yerr=cv_stds, capsize=5, alpha=0.7)\n",
    "plt.title('Model Comparison (Cross-Validation)')\n",
    "plt.ylabel('CV Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance (for Random Forest)\n",
    "if 'Random Forest' in trained_models:\n",
    "    rf_model = trained_models['Random Forest']\n",
    "    feature_importance = rf_model.feature_importances_\n",
    "    feature_names = X.columns\n",
    "    \n",
    "    # Sort features by importance\n",
    "    indices = np.argsort(feature_importance)[::-1]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title('Feature Importance - Random Forest')\n",
    "    plt.bar(range(min(20, len(feature_importance))), \n",
    "             feature_importance[indices[:20]], \n",
    "             align='center')\n",
    "    plt.xticks(range(min(20, len(feature_importance))), \n",
    "               [feature_names[i] for i in indices[:20]], \n",
    "               rotation=45, ha='right')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nTop 10 Most Important Features:\")\n",
    "    for i in range(min(10, len(feature_importance))):\n",
    "        print(f\"{i+1:2d}. {feature_names[indices[i]]:25s}: {feature_importance[indices[i]]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056e6c9f",
   "metadata": {},
   "source": [
    "## 7. Make Predictions and Model Deployment\n",
    "\n",
    "Demonstrate how to use the trained model for real-time distress signal detection and prepare for IoT deployment."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
